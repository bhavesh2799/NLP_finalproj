{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ernie 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume ernie and xlm-r use same pre-train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre software install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddle-ernie\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/83/1081e7f4c9463c87a37d240bc611ce1dfebb19be9a78d81e171bea55642e/paddle-ernie-0.0.4.dev1.tar.gz\n",
      "Requirement already satisfied: requests in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddle-ernie) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddle-ernie) (4.36.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from requests->paddle-ernie) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from requests->paddle-ernie) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from requests->paddle-ernie) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from requests->paddle-ernie) (2.8)\n",
      "Building wheels for collected packages: paddle-ernie\n",
      "  Building wheel for paddle-ernie (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for paddle-ernie: filename=paddle_ernie-0.0.4.dev1-cp37-none-any.whl size=21722 sha256=93107be76671eb1c86c458a23449d17aa5f683328aa26bdf857f8cd19b0ec959\n",
      "  Stored in directory: /Users/charles/Library/Caches/pip/wheels/c4/82/c9/cc31422e3d04d812d968286445a5481d411e855c6c6d24f3a2\n",
      "Successfully built paddle-ernie\n",
      "Installing collected packages: paddle-ernie\n",
      "Successfully installed paddle-ernie-0.0.4.dev1\n"
     ]
    }
   ],
   "source": [
    "!pip install paddle-ernie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Collecting paddlepaddle==1.8.5\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\"))': /pypi/simple/paddlepaddle/\u001b[0m\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/68/4a/f1a19e3fdbd706f438858a112865bf1d172b1d8fba38cfaee156858ef8c7/paddlepaddle-1.8.5-cp37-cp37m-macosx_10_6_intel.whl (46.4MB)\n",
      "\u001b[K     |████████████████████████████████| 46.4MB 1.7MB/s \n",
      "\u001b[?25hCollecting funcsigs (from paddlepaddle==1.8.5)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: astor in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (0.8.1)\n",
      "Requirement already satisfied: pyyaml in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (5.1.2)\n",
      "Requirement already satisfied: scipy; python_version > \"3.5\" in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (1.4.1)\n",
      "Collecting pathlib (from paddlepaddle==1.8.5)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/ac/aa/9b065a76b9af472437a0059f77e8f962fe350438b927cb80184c32f075eb/pathlib-1.0.1.tar.gz (49kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 1.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.12; python_version >= \"3.5\" in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (1.18.0)\n",
      "Requirement already satisfied: opencv-python in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (4.1.2.30)\n",
      "Collecting objgraph (from paddlepaddle==1.8.5)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/a9/79/9f47706447b9ba0003c0680da4fed1d502adf410e1d953b4d1a5d3486640/objgraph-3.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: graphviz in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (0.13.2)\n",
      "Requirement already satisfied: nltk; python_version >= \"3.5\" in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (3.4.5)\n",
      "Collecting rarfile (from paddlepaddle==1.8.5)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/95/f4/c92fab227c7457e3b76a4096ccb655ded9deac869849cb03afbe55dfdc1e/rarfile-4.0-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (3.1.1)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (3.10.0)\n",
      "Collecting gast==0.3.3 (from paddlepaddle==1.8.5)\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: decorator in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (4.4.0)\n",
      "Requirement already satisfied: prettytable in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (0.7.2)\n",
      "Requirement already satisfied: Pillow in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (8.0.1)\n",
      "Requirement already satisfied: six in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from paddlepaddle==1.8.5) (1.13.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.8.5) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.8.5) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.8.5) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.8.5) (2020.4.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle==1.8.5) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle==1.8.5) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle==1.8.5) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle==1.8.5) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /Users/charles/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.1.0->paddlepaddle==1.8.5) (41.4.0)\n",
      "Building wheels for collected packages: pathlib\n",
      "  Building wheel for pathlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathlib: filename=pathlib-1.0.1-cp37-none-any.whl size=14348 sha256=b605f00e3ff54e90c87c61b2f23612fdfb5e5f5ad14d15f0a9986654065dcef0\n",
      "  Stored in directory: /Users/charles/Library/Caches/pip/wheels/37/41/f2/be991aaac17dd855bce2cf77b92722e05b27f782aec549d64c\n",
      "Successfully built pathlib\n",
      "\u001b[31mERROR: tensorflow 1.14.0 has requirement tensorboard<1.15.0,>=1.14.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 1.14.0 has requirement tensorflow-estimator<1.15.0rc0,>=1.14.0rc0, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: funcsigs, pathlib, objgraph, rarfile, gast, paddlepaddle\n",
      "  Found existing installation: gast 0.3.2\n",
      "    Uninstalling gast-0.3.2:\n",
      "      Successfully uninstalled gast-0.3.2\n",
      "Successfully installed funcsigs-1.0.2 gast-0.3.3 objgraph-3.5.0 paddlepaddle-1.8.5 pathlib-1.0.1 rarfile-4.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install paddlepaddle==1.8.5 -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading https://ernie-github.cdn.bcebos.com/model-ernie1.0.1.tar.gz: 788478KB [01:27, 9057.32KB/s]                             \n",
      "[[-1.         -1.          0.99479663 -0.99986964 -0.7872066  -1.\n",
      "  -0.99919444  0.985997   -0.22648102  0.97202295 -0.9994965  -0.982234\n",
      "  -0.6821966  -0.9998574  -0.83046496 -0.9804977  -1.          0.9999509\n",
      "  -0.55144966  0.48973152 -1.          1.          0.14248642 -0.71969527\n",
      "  -0.9055147   0.97965705 -0.999682    0.85135585  1.         -0.39387462\n",
      "  -0.99999905  0.9999919  -0.9992018  -0.09899261  0.99996     0.7490412\n",
      "  -0.9999922  -0.9657562  -0.9960676  -0.95335084  0.9999292  -0.9197153\n",
      "  -0.99989647  0.63038546 -0.9860959  -0.99991727 -1.          0.99999994\n",
      "  -0.99999994 -0.82624584 -0.9744699   0.99909854  1.         -0.9999999\n",
      "  -0.9999997  -0.999507   -0.02157898 -1.          0.99975914  0.9932416\n",
      "  -0.99919933 -1.          1.          0.39329714 -0.31263566 -0.9984498\n",
      "  -0.9835464  -0.9999865  -0.98631394  0.99999607  0.98583347 -0.99960685\n",
      "  -0.9474886  -0.99999726  1.         -0.9858534   0.688139    1.\n",
      "   0.99902004  0.9886897   1.          0.99939877 -0.99691194  0.9998407\n",
      "   1.         -1.         -0.999989    0.9622676   1.         -0.9073396\n",
      "  -0.9999989   0.41061106  0.35902512  0.97015893  1.         -1.\n",
      "   0.99992687 -0.0964089   0.99978644  1.         -0.530104    0.9979866\n",
      "  -0.9999991   0.99999976 -0.569061   -1.          1.         -1.\n",
      "  -0.8341091  -0.9972185   0.7137046   0.6173493   0.99986655  1.\n",
      "   1.         -0.99914074 -0.9982252  -0.29370782  0.9498659   0.974079\n",
      "  -0.97978586  0.9999881  -0.9997873   0.89261305 -0.999963    0.9875354\n",
      "   0.9999668  -0.9995632  -0.7013648   0.9091246   0.9999299   0.36666223\n",
      "  -0.99957234 -0.9999999   0.99990904  0.9999945   0.9999999  -0.9953213\n",
      "   1.          0.9722779   1.          0.9999953  -0.7862495   0.9995345\n",
      "   0.8351892   0.9918631   0.9650966  -0.99940604 -0.9712901  -0.99475235\n",
      "   0.9923304   0.9999903   0.8533538  -0.9400228  -0.9748845   1.\n",
      "   1.         -1.          0.9351647   0.9987284   1.          0.999715\n",
      "  -0.9965259  -0.54677594  1.          0.99421793  0.60691833 -1.\n",
      "   0.9966893  -0.94738007 -0.99999994  0.9986268   0.999989    1.\n",
      "  -1.         -0.527316    0.04165652  0.9937646   0.88374025 -1.\n",
      "  -0.9889255   1.          0.99999416 -1.         -0.73221725  0.8570928\n",
      "  -0.999245    0.35026038  0.98152554 -0.99999976  0.7171257   0.97186583\n",
      "  -0.9991775   0.9970284  -0.9999528  -0.7097994  -0.999998   -0.96868265\n",
      "  -0.3610324  -0.9055083   0.9993948  -0.49309695  0.99990445 -0.9978073\n",
      "   0.7300043   0.9939311  -0.98935276 -0.9945301   0.99832517 -0.97943145\n",
      "   0.53081536 -0.99797535 -0.95295066  0.99999845 -0.99999976 -0.7356121\n",
      "   0.8141547   1.          0.9892449  -0.8346806  -1.          0.9997429\n",
      "  -0.8681047  -0.9997559  -0.20181328 -0.9999955  -0.9999992  -0.21824215\n",
      "   0.9998733   1.          0.9999924  -0.99840605  0.9407251   0.4017578\n",
      "  -0.9992026  -0.82429636 -0.942953    0.99978983  0.7694285   0.9777225\n",
      "   0.99998903 -1.          0.8595468   0.99960047 -0.99676716 -0.999433\n",
      "  -0.999798    0.99998605  0.9996594  -0.9996685  -0.96993804  0.7935618\n",
      "  -0.45320496  0.9830855  -0.5497208   0.99300534  0.99988496  1.\n",
      "  -0.9999993  -1.         -0.99618727  0.2331469  -0.99719536 -0.806616\n",
      "   0.32800168  1.          0.9999986  -0.9734314  -1.          0.9978575\n",
      "  -0.9919796   0.99999815 -1.         -0.13344261  1.         -0.9996104\n",
      "   0.997187   -0.9864563   0.16868863 -0.99276286  0.9999972   0.9200264\n",
      "  -0.9242952  -0.9999326   0.9988716  -0.97259337 -1.         -1.\n",
      "  -1.          0.99693316  0.9999597   0.9950433   0.8853865   0.9835156\n",
      "   0.9997289   0.99856824 -0.9649252  -0.9971054  -1.         -1.\n",
      "  -0.8998267  -0.9311264  -0.97404075  0.2537211  -1.         -0.9191791\n",
      "  -0.999935    0.9993159   1.         -1.          0.02620407 -0.99809736\n",
      "   0.99772954  1.         -1.          0.9999909   0.992443    0.9997116\n",
      "  -1.          0.9988211  -0.50127405  1.         -0.98255926 -0.8043855\n",
      "   0.99980813 -0.62940586 -0.9998867  -0.9706199   0.9978045  -0.6076609\n",
      "  -1.          1.         -0.9982328   0.99958396 -0.86450344 -0.76214844\n",
      "  -0.9998825   0.9517749  -0.8212135   0.29458448 -0.9982294   1.\n",
      "   1.          0.9689296   0.9927623  -0.9999997  -0.999273    1.\n",
      "  -0.99918365  0.81404096  0.6913403   0.93894166 -0.80623263  0.9999998\n",
      "   0.94318366 -0.9999073   0.98991054 -0.96207523 -0.20486738 -0.9984225\n",
      "  -0.39250657 -0.99386454  0.19342794  0.997843    0.9914832   1.\n",
      "   1.         -0.9217593  -1.          0.777627    0.92064124 -1.\n",
      "  -0.99893475 -0.46215075  0.9996879   0.80873096 -0.20582005  0.8834874\n",
      "   0.99975884  0.99866796 -0.9922761  -0.99996084  0.9998694  -0.82793516\n",
      "  -0.9984104  -0.9990964   0.9821191   1.         -0.9999998   0.9961604\n",
      "   0.99999976 -0.9999925  -0.9999998  -0.99999714  1.          0.99393135\n",
      "   0.9915205   0.99771667 -0.9999975   1.          0.98841125 -1.\n",
      "  -1.0000001   0.9928691   0.73384243 -1.         -0.9997164  -0.9977229\n",
      "   1.          0.9964063  -0.9999788   0.9579225   0.9986261  -0.9591689\n",
      "  -0.9325816   1.          0.9999817  -0.99965525 -0.05712062  0.79292655\n",
      "   1.         -1.         -0.63294464  0.999999    0.99999285 -0.9138506\n",
      "  -0.5814281  -0.99999756 -0.5022545  -0.9884215   0.62459964  0.99521846\n",
      "  -0.9662706   0.99879575  0.9193486   0.8657088  -0.7023969   0.99981546\n",
      "   1.          0.93622845  0.88115585 -0.8053172  -0.5261445   0.9999964\n",
      "   0.715626    0.6508105  -1.          0.9999997   0.97201794  0.08372381\n",
      "  -0.9537236  -0.98426497  0.80216944 -0.99989307  0.13942847  0.9476907\n",
      "   0.33132333  0.9190517  -0.64562154 -0.99998987  1.          1.\n",
      "   0.99966234  1.          0.980936    0.95855546 -0.99999714 -0.9999968\n",
      "  -0.77135634 -0.3200992  -1.         -0.8165568  -0.9010419  -0.91434294\n",
      "   0.9901419  -0.99999976  0.9999962  -0.9999999  -0.99835294 -0.7945876\n",
      "  -1.          0.9976138  -0.99917233  0.9999998   0.9976408  -0.9043437\n",
      "  -0.7195391   0.39754698  0.9692617   0.99999946  0.7809398   0.99996823\n",
      "   0.20420422  0.9471513   1.         -0.93191314 -0.99999994  0.9995098\n",
      "   0.04715961 -0.99948186 -0.42997736  1.          0.99354094 -0.92046833\n",
      "  -1.         -0.999862    0.94526565 -1.         -0.93060166 -0.9613411\n",
      "   0.92313194 -1.          0.9980211  -1.         -0.96500164 -0.999843\n",
      "   0.9979359   0.99998164 -1.          1.          0.99999267 -0.6386361\n",
      "   0.9985997  -0.99998957  0.9899823   0.9999999  -0.99988794 -0.99999815\n",
      "  -0.8187792   0.96947473 -0.99999994 -0.99999005 -0.9998917  -0.99973357\n",
      "   0.7184288  -0.9999977  -0.9999689  -0.24213035 -0.9999994   0.8264486\n",
      "   1.          0.9999992  -0.99702954  0.99994653  0.44653425  0.9999995\n",
      "   0.9047353   0.9982966   0.562305    1.         -1.         -0.9999001\n",
      "   0.9843749  -1.         -0.99825895  1.         -0.99998605 -0.9999753\n",
      "   0.9998784   1.         -0.9999597   0.94500023 -0.23792751 -0.8770328\n",
      "  -1.         -0.98388237 -0.99546325 -1.          0.952634   -0.9994246\n",
      "  -0.9998663  -0.9999824   0.9992353   0.995237    0.7922422   0.893773\n",
      "  -0.9999905  -0.99992734  0.96328115  0.9943541   0.9941962  -0.9999979\n",
      "   1.         -0.99741834  0.99996305 -0.29181513  0.9977631   0.98274726\n",
      "   0.9976778   1.          0.90089697  0.26522997 -0.99365455  1.\n",
      "  -0.9140641  -1.          0.98997015 -0.99999994 -1.          0.98956054\n",
      "   0.98788255  0.99736536 -0.99629045 -0.99829906  0.17212166 -0.9996059\n",
      "   0.0579397  -1.          0.9999997   0.9912049  -1.         -0.9885665\n",
      "  -0.9902784  -0.7572869   0.99752456 -0.17518866 -0.9912978  -0.99999326\n",
      "   0.99997234 -0.99999934 -0.8279126   0.98660254  0.99603254 -0.6756357\n",
      "  -0.7336667   1.          1.         -0.9998628   0.8316436  -0.36662844\n",
      "   0.6111804   0.9988031   0.9810423  -0.9588541   0.9994683   0.99999875\n",
      "  -0.9996056   0.9680579   0.10139739 -1.         -0.99993306  0.56645495\n",
      "   0.99999994 -0.9979601  -0.9999975   0.9998277  -0.999281   -0.99696416\n",
      "   0.99998325 -0.9999965   1.          1.         -0.9471592  -0.99986416\n",
      "   0.99730974  1.          0.9552294   0.9998091   0.99668235  0.99999964\n",
      "   1.         -0.9913356  -0.9999403   1.          0.92216367  0.99584055\n",
      "   0.98467463 -0.9994917   0.94751537  0.99999064  0.9875233   0.999985\n",
      "  -0.99707204 -1.          0.06024247  0.91710323 -0.99998903  1.\n",
      "   0.9999999  -0.7093202   0.99872446  0.9995061   0.32136896  0.9317001\n",
      "   1.         -0.9996941   0.9998096  -0.9960457   0.91744417  0.9999964\n",
      "   0.999698   -0.98548484 -0.9975593   0.88404953 -0.9254098  -0.9993419\n",
      "  -0.81233263  0.90769243 -0.9911981   0.50136054  0.99026996 -0.9805376\n",
      "  -0.9999451   0.9848072   0.38554856 -0.55921793  0.99018514  0.8039647\n",
      "   1.         -1.         -0.999719    0.8011266   0.67730385  0.99545497\n",
      "   0.9999696   0.9993313   0.00101653 -0.99999917  0.996108   -0.99704945\n",
      "   0.99996704 -0.9999998  -1.          0.9997395   0.98511857  0.99999493\n",
      "   1.          0.9961428   0.9999974   0.9982907  -0.79178387  0.99584574\n",
      "  -0.99146515 -1.          0.99999976  1.          0.99999505  0.14218065\n",
      "   0.99049294 -1.         -0.99067855  0.99999744 -0.9953327   0.98921716\n",
      "   0.93848914  0.8418771   1.          0.99999803  0.9800671   0.99886674\n",
      "   0.9999988   0.99946415  0.9849099   0.9996924  -0.79442227 -0.9999412\n",
      "   0.99827075  1.         -0.05767363  0.99999857  0.8176171   0.7983498\n",
      "  -0.14292054  1.         -0.99759513 -0.9999982  -0.99973375 -0.9993742 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import paddle.fluid.dygraph as D\n",
    "from ernie.tokenizing_ernie import ErnieTokenizer\n",
    "from ernie.modeling_ernie import ErnieModel\n",
    "\n",
    "D.guard().__enter__() # activate paddle `dygrpah` mode\n",
    "\n",
    "model = ErnieModel.from_pretrained('ernie-1.0')    # Try to get pretrained model from server, make sure you have network connection\n",
    "model.eval()\n",
    "tokenizer = ErnieTokenizer.from_pretrained('ernie-1.0')\n",
    "\n",
    "ids, _ = tokenizer.encode('hello world')\n",
    "ids = D.to_variable(np.expand_dims(ids, 0))  # insert extra `batch` dimension\n",
    "pooled, encoded = model(ids)                 # eager execution\n",
    "print(pooled.numpy())                        # convert  results to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ERNIE'...\n",
      "remote: Enumerating objects: 7, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "Receiving objects: 100% (1880/1880), 88.77 MiB | 33.00 KiB/s, done.\n",
      "remote: Total 1880 (delta 1), reused 0 (delta 0), pack-reused 1873\n",
      "Resolving deltas: 100% (1023/1023), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PaddlePaddle/ERNIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add preprocessing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import struct\n",
    "import random as r\n",
    "import re\n",
    "import gzip\n",
    "import logging\n",
    "from itertools import accumulate\n",
    "from functools import reduce, partial, wraps\n",
    "from propeller import log\n",
    "from propeller.paddle.data import feature_pb2, example_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Pre Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'hindi-english/train_14k_split_conll.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_segs(segment_piece):\n",
    "    if len(segment_piece) == 0:\n",
    "        return []\n",
    "    else:\n",
    "        return [min(segment_piece)] * len(segment_piece)\n",
    "\n",
    "whit_space_pat = re.compile(r'\\S+')\n",
    "def segment(inputs, inputs_segment):\n",
    "    ret = [r.span() for r in whit_space_pat.finditer(inputs)]\n",
    "    ret = [(inputs[s: e], gen_segs(inputs_segment[s: e])) for i, (s, e) in enumerate(ret)]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sen, seg_info):\n",
    "    sen = sen.lower()\n",
    "    res_word, res_segments = [], []\n",
    "    for match in pat.finditer(sen):\n",
    "        words, pos = _wordpiece(match.group(0), vocab=vocab_set, unk_token='[UNK]')\n",
    "        start_of_word = match.span()[0]\n",
    "        for w, p in zip(words, pos):\n",
    "            res_word.append(w)\n",
    "            res_segments.append(gen_segs(seg_info[p[0] + start_of_word: p[1] + start_of_word]))\n",
    "    return res_word, res_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_txt(line):\n",
    "    if len(line) == 0:\n",
    "        return []\n",
    "    line = line.decode('utf8')\n",
    "    ret_line, ret_seginfo = [], []\n",
    "\n",
    "    for l, i in segment(line, list(range(len(line)))):\n",
    "        for ll, ii in zip(*tokenize(l, i)):\n",
    "            ret_line.append(ll)\n",
    "            ret_seginfo.append(ii)\n",
    "\n",
    "    if args.check and r.random() < 0.005:\n",
    "        print('****', file=sys.stderr)\n",
    "        print(line, file=sys.stderr)\n",
    "        print('|'.join(ret_line), file=sys.stderr)\n",
    "        print(ret_seginfo, file=sys.stderr)\n",
    "        print('****', file=sys.stderr)\n",
    "\n",
    "    ret_line = [vocab.get(r, vocab['[UNK]']) for r in ret_line]\n",
    "    ret_seginfo = [[-1] if i == [] else i for i in ret_seginfo] #for sentence piece only\n",
    "    ret_seginfo = [min(i) for i in ret_seginfo]\n",
    "    return ret_line, ret_seginfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_example(slots):\n",
    "    txt, seginfo = slots\n",
    "    txt_fe_list = feature_pb2.FeatureList(feature=[feature_pb2.Feature(int64_list=feature_pb2.Int64List(value=t)) for t in txt])\n",
    "    segsinfo_fe_list = feature_pb2.FeatureList(feature=[feature_pb2.Feature(int64_list=feature_pb2.Int64List(value=s)) for s in seginfo])\n",
    "    assert len(txt_fe_list.feature) == len(segsinfo_fe_list.feature), 'txt[%d] and seginfo[%d] size not match' % (len(txt_fe_list.feature), len(segsinfo_fe_list.feature))\n",
    "    features = {\n",
    "        'txt':  txt_fe_list,\n",
    "        'segs': segsinfo_fe_list,\n",
    "    }\n",
    "\n",
    "    ex = example_pb2.SequenceExample(feature_lists=feature_pb2.FeatureLists(feature_list=features))\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gz(serialized, to_file):\n",
    "    l = len(serialized)\n",
    "    packed_data = struct.pack('i%ds' % l, l, serialized)\n",
    "    to_file.write(packed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bb(from_file, to_file):\n",
    "    slots = []\n",
    "    for i, line in enumerate(from_file):\n",
    "        line = line.strip()\n",
    "        if args.verbose and i % 10000 == 0:\n",
    "            log.debug(i)\n",
    "        if len(line) == 0:\n",
    "            if len(slots) != 0:\n",
    "                transposed_slots = list(zip(*slots))\n",
    "                ex = build_example(transposed_slots)\n",
    "                write_gz(ex.SerializeToString(), to_file)\n",
    "                slots = []\n",
    "            continue\n",
    "        parsed_line = parse_txt(line)\n",
    "        slots.append(parsed_line)\n",
    "\n",
    "    if len(slots) != 0:\n",
    "        transposed_slots = list(zip(*slots))\n",
    "        ex = build_example(transposed_slots)\n",
    "        write_gz(ex.SerializeToString(), to_file)\n",
    "        slots = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ernie.tokenizing_ernie import _wordpiece\n",
    "    pat = re.compile(r'([a-zA-Z0-9]+|\\S)')\n",
    "\n",
    "    vocab = {j.strip().split(b'\\t')[0].decode('utf8'): i for i, j in enumerate(open(args.vocab, 'rb'))}\n",
    "    vocab_set = set(vocab.keys())\n",
    "\n",
    "\n",
    "    with open(path, 'rb') as from_file, gzip.open(args.tgt, 'wb') as to_file:\n",
    "        #log.info('making gz from bb %s ==> %s' % (from_file, to_file))\n",
    "        build_bb(from_file, to_file)\n",
    "        #log.info('done: %s' % to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "        raise ValueError('--from_pretrained not found: %s' % args.from_pretrained)\n",
    "    cfg_file_path = os.path.join(args.from_pretrained, 'ernie_config.json')\n",
    "    param_path = os.path.join(args.from_pretrained, 'params')\n",
    "    vocab_path = os.path.join(args.from_pretrained, 'vocab.txt')\n",
    "    assert os.path.exists(cfg_file_path) and os.path.exists(param_path) and os.path.exists(vocab_path)\n",
    "\n",
    "\n",
    "    hparams_cli = propeller.parse_hparam(args)\n",
    "    hparams_config_file = json.loads(open(cfg_file_path).read())\n",
    "    default_hparams = propeller.HParams(\n",
    "        batch_size=50,\n",
    "        warmup_steps=10000,\n",
    "        learning_rate=1e-4,\n",
    "        weight_decay=0.01,\n",
    "        use_fp16=False,\n",
    "    )\n",
    "\n",
    "    hparams = default_hparams.join(propeller.HParams(**hparams_config_file)).join(hparams_cli)\n",
    "\n",
    "    default_run_config=dict(\n",
    "        max_steps=1000000,\n",
    "        save_steps=10000,\n",
    "        log_steps=10,\n",
    "        max_ckpt=3,\n",
    "        skip_steps=0,\n",
    "        eval_steps=-1)\n",
    "\n",
    "    run_config = dict(default_run_config, **json.loads(args.run_config))\n",
    "    run_config = propeller.RunConfig(**run_config)\n",
    "\n",
    "    tokenizer = ErnieTokenizer.from_pretrained(args.from_pretrained)\n",
    "\n",
    "\n",
    "    train_ds = make_pretrain_dataset('train', args.data_dir,\n",
    "            vocab=tokenizer.vocab, hparams=hparams, args=args)\n",
    "\n",
    "    seq_shape = [-1, args.max_seqlen]\n",
    "    ints_shape = [-1,]\n",
    "    shapes = (seq_shape, seq_shape, ints_shape, [-1, 2], ints_shape) \n",
    "    types = ('int64', 'int64', 'int64', 'int64', 'int64')\n",
    "\n",
    "    train_ds.data_shapes = shapes\n",
    "    train_ds.data_types = types\n",
    "    ws = None\n",
    "\n",
    "    varname_to_warmstart = re.compile(r'.*')\n",
    "    if args.from_pretrained is not None:\n",
    "        warm_start_dir = os.path.join(args.from_pretrained, 'params')\n",
    "        ws = propeller.WarmStartSetting(\n",
    "                predicate_fn=lambda v: varname_to_warmstart.match(v.name) and os.path.exists(os.path.join(warm_start_dir, v.name)),\n",
    "                from_dir=warm_start_dir\n",
    "            )\n",
    "\n",
    "    ernie_learner = propeller.Learner(ernie_pretrain_model_fn, run_config, params=hparams, warm_start_setting=ws)\n",
    "    ernie_learner.train(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ernie 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, mode, params, run_config):\n",
    "    ernie = ErnieModelForSequenceClassification(params, name='')\n",
    "    if not params is propeller.RunMode.TRAIN:\n",
    "        ernie.eval()\n",
    "\n",
    "    metrics, loss = None, None\n",
    "    if mode is propeller.RunMode.PREDICT:\n",
    "        src_ids, sent_ids = features\n",
    "        _, logits = ernie(src_ids, sent_ids)\n",
    "        predictions = [logits,]\n",
    "    else:\n",
    "        src_ids, sent_ids, labels = features\n",
    "        if mode is propeller.RunMode.EVAL:\n",
    "            loss, logits = ernie(src_ids, sent_ids, labels=labels)\n",
    "            pred = L.argmax(logits, axis=1)\n",
    "            acc = propeller.metrics.Acc(labels, pred)\n",
    "            metrics = {'acc': acc}\n",
    "            predictions = [pred]\n",
    "        else:\n",
    "            loss, logits = ernie(src_ids, sent_ids, labels=labels)\n",
    "            scheduled_lr, _ = optimization(\n",
    "                loss=loss,\n",
    "                warmup_steps=int(run_config.max_steps * params['warmup_proportion']),\n",
    "                num_train_steps=run_config.max_steps,\n",
    "                learning_rate=params['learning_rate'],\n",
    "                train_program=F.default_main_program(), \n",
    "                startup_prog=F.default_startup_program(),\n",
    "                use_fp16=params.use_fp16,\n",
    "                weight_decay=params['weight_decay'],\n",
    "                scheduler=\"linear_warmup_decay\",\n",
    "                )\n",
    "            propeller.summary.scalar('lr', scheduled_lr)\n",
    "            predictions = [logits,]\n",
    "\n",
    "    return propeller.ModelSpec(loss=loss, mode=mode, metrics=metrics, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(args.from_pretrained):\n",
    "        raise ValueError('--from_pretrained not found: %s' % args.from_pretrained)\n",
    "    cfg_file_path = os.path.join(args.from_pretrained, 'ernie_config.json')\n",
    "    param_path = os.path.join(args.from_pretrained, 'params')\n",
    "    vocab_path = os.path.join(args.from_pretrained, 'vocab.txt')\n",
    "\n",
    "    assert os.path.exists(cfg_file_path) and os.path.exists(param_path) and os.path.exists(vocab_path)\n",
    "\n",
    "    hparams_cli = propeller.parse_hparam(args)\n",
    "    hparams_config_file = json.loads(open(cfg_file_path).read())\n",
    "    default_hparams = propeller.HParams(\n",
    "        batch_size=32,\n",
    "        num_labels=3,\n",
    "        warmup_proportion=0.1,\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.01,\n",
    "        use_task_id=False,\n",
    "        use_fp16=args.use_fp16,\n",
    "    )\n",
    "\n",
    "    hparams = default_hparams.join(propeller.HParams(**hparams_config_file)).join(hparams_cli)\n",
    "\n",
    "    default_run_config=dict(\n",
    "        max_steps=args.epoch * 390000 / hparams.batch_size,\n",
    "        save_steps=1000,\n",
    "        log_steps=10,\n",
    "        max_ckpt=1,\n",
    "        skip_steps=0,\n",
    "        model_dir=tempfile.mkdtemp(),\n",
    "        eval_steps=100)\n",
    "    run_config = dict(default_run_config, **json.loads(args.run_config))\n",
    "    run_config = propeller.RunConfig(**run_config)\n",
    "\n",
    "    tokenizer = ErnieTokenizer.from_pretrained(args.from_pretrained)\n",
    "    #tokenizer = ErnieTinyTokenizer.from_pretrained(args.from_pretrained)\n",
    "    unk_id = tokenizer.vocab['[UNK]']\n",
    "\n",
    "    shapes = ([-1, args.max_seqlen], [-1, args.max_seqlen], [-1])\n",
    "    types = ('int64', 'int64', 'int64')\n",
    "    if not args.do_predict:\n",
    "        feature_column = propeller.data.FeatureColumns([\n",
    "            propeller.data.TextColumn('title', unk_id=unk_id, vocab_dict=tokenizer.vocab, tokenizer=tokenizer.tokenize),\n",
    "            propeller.data.TextColumn('comment', unk_id=unk_id, vocab_dict=tokenizer.vocab, tokenizer=tokenizer.tokenize),\n",
    "            propeller.data.LabelColumn('label', vocab_dict={\n",
    "                b\"contradictory\": 0,\n",
    "                b\"contradiction\": 0,\n",
    "                b\"entailment\": 1,\n",
    "                b\"neutral\": 2,\n",
    "            }),\n",
    "        ])\n",
    "\n",
    "        def map_fn(seg_a, seg_b, label):\n",
    "            seg_a, seg_b = tokenizer.truncate(seg_a, seg_b, seqlen=args.max_seqlen)\n",
    "            sentence, segments = tokenizer.build_for_ernie(seg_a, seg_b)\n",
    "            #label = np.expand_dims(label, -1) #\n",
    "            return sentence, segments, label\n",
    "\n",
    "        train_ds = feature_column.build_dataset('train', data_dir=os.path.join(args.data_dir, 'train'), shuffle=True, repeat=True, use_gz=False) \\\n",
    "                                       .map(map_fn) \\\n",
    "                                       .padded_batch(hparams.batch_size) \n",
    "\n",
    "        dev_ds = feature_column.build_dataset('dev', data_dir=os.path.join(args.data_dir, 'dev'), shuffle=False, repeat=False, use_gz=False) \\\n",
    "                                       .map(map_fn) \\\n",
    "                                       .padded_batch(hparams.batch_size) \n",
    "\n",
    "        test_ds = feature_column.build_dataset('test', data_dir=os.path.join(args.data_dir, 'test'), shuffle=False, repeat=False, use_gz=False) \\\n",
    "                                       .map(map_fn) \\\n",
    "                                       .padded_batch(hparams.batch_size) \\\n",
    "\n",
    "        train_ds.data_shapes = shapes\n",
    "        train_ds.data_types = types\n",
    "        dev_ds.data_shapes = shapes\n",
    "        dev_ds.data_types = types\n",
    "        test_ds.data_shapes = shapes\n",
    "        test_ds.data_types = types\n",
    "\n",
    "        varname_to_warmstart = re.compile(r'^encoder.*[wb]_0$|^.*embedding$|^.*bias$|^.*scale$|^pooled_fc.[wb]_0$')\n",
    "\n",
    "        ws = propeller.WarmStartSetting(\n",
    "                predicate_fn=lambda v: varname_to_warmstart.match(v.name) and os.path.exists(os.path.join(param_path, v.name)),\n",
    "                from_dir=param_path,\n",
    "            )\n",
    "\n",
    "        best_exporter = propeller.train.exporter.BestExporter(os.path.join(run_config.model_dir, 'best'), cmp_fn=lambda old, new: new['dev']['acc'] > old['dev']['acc'])\n",
    "        propeller.train.train_and_eval(\n",
    "                model_class_or_model_fn=model_fn,\n",
    "                params=hparams, \n",
    "                run_config=run_config, \n",
    "                train_dataset=train_ds, \n",
    "                eval_dataset={'dev': dev_ds, 'test': test_ds}, \n",
    "                warm_start_setting=ws, \n",
    "                exporters=[best_exporter])\n",
    "\n",
    "        print('dev_acc3\\t%.5f\\ntest_acc3\\t%.5f' % (best_exporter._best['dev']['acc'], best_exporter._best['test']['acc']))\n",
    "\n",
    "    else:\n",
    "        feature_column = propeller.data.FeatureColumns([\n",
    "            propeller.data.TextColumn('title', unk_id=unk_id, vocab_dict=tokenizer.vocab, tokenizer=tokenizer.tokenize),\n",
    "            propeller.data.TextColumn('comment', unk_id=unk_id, vocab_dict=tokenizer.vocab, tokenizer=tokenizer.tokenize),\n",
    "        ])\n",
    "\n",
    "        def map_fn(seg_a, seg_b):\n",
    "            seg_a, seg_b = tokenizer.truncate(seg_a, seg_b, seqlen=args.max_seqlen)\n",
    "            sentence, segments = tokenizer.build_for_ernie(seg_a, seg_b)\n",
    "            return sentence, segments\n",
    "\n",
    "\n",
    "        predict_ds = feature_column.build_dataset_from_stdin('predict') \\\n",
    "                               .map(map_fn) \\\n",
    "                               .padded_batch(hparams.batch_size) \\\n",
    "\n",
    "        predict_ds.data_shapes = shapes[: -1]\n",
    "        predict_ds.data_types = types[: -1]\n",
    "\n",
    "        est = propeller.Learner(model_fn, run_config, hparams)\n",
    "        for res, in est.predict(predict_ds, ckpt=-1):\n",
    "            print('%d\\t%.5f\\t%.5f\\t%.5f' % (np.argmax(res), res[0], res[1], res[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xlm-r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train with pre-train data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
