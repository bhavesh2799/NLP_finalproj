{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "name": "XLM-R_train_hindi.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e0b7ecfe365e4e3d955cd5d6dbfacb54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_4d24a14e8d1f48d48792a3df697a7a8a",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_e5cee6220bed47be8149551bbe553c3f",
       "IPY_MODEL_cbb0e737a98a41ff9242872f6373d99a"
      ]
     }
    },
    "4d24a14e8d1f48d48792a3df697a7a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e5cee6220bed47be8149551bbe553c3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_478a11aa4910482689024d626e24db22",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 5069051,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 5069051,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_c14ddf8a9b824b378af29e4ffa23f25d"
     }
    },
    "cbb0e737a98a41ff9242872f6373d99a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_e424f070155e4c219f27cfe58ba54a9c",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 5.07M/5.07M [00:18&lt;00:00, 277kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_39652f05dc7c46d5ab26bd76000a4218"
     }
    },
    "478a11aa4910482689024d626e24db22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "c14ddf8a9b824b378af29e4ffa23f25d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e424f070155e4c219f27cfe58ba54a9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "39652f05dc7c46d5ab26bd76000a4218": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d1e9a71fdb634b1d87c4e218a0fb9910": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_a4846c41c1fa4aaa87bce227b543e5d3",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_5542e0feea1e4e3eb148a60ea5664b69",
       "IPY_MODEL_1f151561e0a445e981a638e0a57d5ec7"
      ]
     }
    },
    "a4846c41c1fa4aaa87bce227b543e5d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "5542e0feea1e4e3eb148a60ea5664b69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_6413695f7ed34b55b6f99bee78167c81",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 512,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 512,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_5f6061b7ed3948cabbf0502b94c51eac"
     }
    },
    "1f151561e0a445e981a638e0a57d5ec7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_13b84960c1eb4aa6a1b16100169837a7",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 512/512 [00:00&lt;00:00, 4.34kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_91f8c6c889844ecc9e814fa58259d019"
     }
    },
    "6413695f7ed34b55b6f99bee78167c81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "5f6061b7ed3948cabbf0502b94c51eac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "13b84960c1eb4aa6a1b16100169837a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "91f8c6c889844ecc9e814fa58259d019": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "01dc2d915c1940e192794e7e7ec87510": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_f4fef47096c244ada00d977c1781b974",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_2f282310f3fb4b86825cd9f76fca5373",
       "IPY_MODEL_73e2eccfe6724fd18b05d819f4b14b3b"
      ]
     }
    },
    "f4fef47096c244ada00d977c1781b974": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "2f282310f3fb4b86825cd9f76fca5373": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_4d00c38ad68a48e0865f736e90e97d7a",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 1115590446,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1115590446,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_d4a7c5861e654694b59e67f5bb6e2f27"
     }
    },
    "73e2eccfe6724fd18b05d819f4b14b3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_91d21b99273c47deaf1c763548f9a4a1",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1.12G/1.12G [00:18&lt;00:00, 60.7MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_bf51f6bc4c7d46f79de55e6d42b4b7eb"
     }
    },
    "4d00c38ad68a48e0865f736e90e97d7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "d4a7c5861e654694b59e67f5bb6e2f27": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "91d21b99273c47deaf1c763548f9a4a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "bf51f6bc4c7d46f79de55e6d42b4b7eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQucnk8OSpBx"
   },
   "source": [
    "# XLM-Roberta Sentiment Analysis\n",
    "## Hindi-English"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OL9lEyMtSpB1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605298436599,
     "user_tz": 420,
     "elapsed": 337,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "9f1e649e-2183-45a4-b554-5f94ca8a256a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    }
   },
   "source": [
    "import sys\n",
    "sys.version"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'3.6.9 (default, Oct  8 2020, 12:12:24) \\n[GCC 8.4.0]'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 1
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Vc9zktwuTG5X",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605394062227,
     "user_tz": 420,
     "elapsed": 19098,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "d520d671-4713-454d-f5e2-5cf18ec008a1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "afk_Td5xTxAO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605394071468,
     "user_tz": 420,
     "elapsed": 7209,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "487653e9-be70-4bab-8efe-ace839b44996",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "%cd drive/My\\ Drive/NLP_finalproj/NLP_finalproj\n",
    "!ls\n",
    "!pip3 install transformers\n"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/NLP_finalproj/NLP_finalproj\n",
      "data  preprocessing  README.md\tXLM-R_train_hindi.ipynb\n",
      "Collecting transformers\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
      "\u001B[K     |████████████████████████████████| 1.3MB 20.7MB/s \n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Collecting sacremoses\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001B[K     |████████████████████████████████| 890kB 49.8MB/s \n",
      "\u001B[?25hCollecting sentencepiece==0.1.91\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001B[K     |████████████████████████████████| 1.1MB 47.9MB/s \n",
      "\u001B[?25hCollecting tokenizers==0.9.3\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001B[K     |████████████████████████████████| 2.9MB 52.8MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=7250887ac3afef27acd37484fa1b0cbf7a66d68b6d91018f9f1089f1bb1b22d9\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "pLmnQSbiSpCC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605394085226,
     "user_tz": 420,
     "elapsed": 10629,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "07b4b003-6ab3-4d24-90d8-14a03ed2c01c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# import our packages...\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "pWhgFkYqSpCJ"
   },
   "source": [
    "## Parsing data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-LJ8s9KASpCK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605394100082,
     "user_tz": 420,
     "elapsed": 1171,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "b0748019-16e8-438b-dd32-87ed1f18430d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets into a pandas dataframe.\n",
    "df_train = pd.read_csv(\"data/hindi-english/train_14k_split.csv\" )\n",
    "df_val = pd.read_csv(\"data/hindi-english/val_3k_split.csv\" )\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences in training set: {:,}\\n'.format(df_train.shape[0]))\n",
    "print('Number of training sentences in val set: {:,}\\n'.format(df_val.shape[0]))\n",
    "\n",
    "# Get the lists of sentences and their labels for train and val datasets\n",
    "sentences_train = df_train.sentence.values\n",
    "labels_train = df_train.label.values\n",
    "sentences_val = df_val.sentence.values\n",
    "labels_val = df_val.label.values\n",
    "\n",
    "print('Train dataset: \\n', df_train.head())\n",
    "print('Val dataset: \\n',df_val.head())"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Number of training sentences in training set: 13,935\n",
      "\n",
      "Number of training sentences in val set: 2,988\n",
      "\n",
      "Train dataset: \n",
      "       id                                           sentence  label sentiment\n",
      "0   4330  nen á vist bolest vztek smutek zmatek osam ě l...      1   neutral\n",
      "1  41616  Haan yaar neha pensive pensive kab karega woh ...      1   neutral\n",
      "2   6648  television media congress ke liye nhi h Ye toh...      0  negative\n",
      "3   2512  All India me nrc lagu kare w Kashmir se dhara ...      2  positive\n",
      "4    610  who Pagal hai kya They aren t real issues Mand...      1   neutral\n",
      "Val dataset: \n",
      "       id                                           sentence  label sentiment\n",
      "0  30258  modi mantrimandal may samil honay par badhai n...      2  positive\n",
      "1  16648                Rashid Tu toh naamakool hai Mare h       0  negative\n",
      "2  28511  U saw caste and religion in them nation saw ta...      0  negative\n",
      "3  10466  sir local police station pe complaint krne par...      1   neutral\n",
      "4  19266  Ve Maahi song from Kesari is current favourite...      2  positive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wm6m3OJRSpCP"
   },
   "source": [
    "## Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "anNHRI3YSpCQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605394105405,
     "user_tz": 420,
     "elapsed": 2392,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "01ecc2f7-5e8d-4281-a5ba-3d0a5b2a8a68",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205,
     "referenced_widgets": [
      "e0b7ecfe365e4e3d955cd5d6dbfacb54",
      "4d24a14e8d1f48d48792a3df697a7a8a",
      "e5cee6220bed47be8149551bbe553c3f",
      "cbb0e737a98a41ff9242872f6373d99a",
      "478a11aa4910482689024d626e24db22",
      "c14ddf8a9b824b378af29e4ffa23f25d",
      "e424f070155e4c219f27cfe58ba54a9c",
      "39652f05dc7c46d5ab26bd76000a4218"
     ]
    }
   },
   "source": [
    "from transformers import XLMRobertaTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading XLMRobertaTokenizer ...')\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)\n",
    "tokenized_train = tokenizer.tokenize(sentences_train[0])\n",
    "tokenized_ids_train = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0]))\n",
    "tokenized_val = tokenizer.tokenize(sentences_val[0])\n",
    "tokenized_ids_val = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_val[0]))\n",
    "\n",
    "# Print the original train sentence; tokenized and IDs mapped.\n",
    "print('Original Train Sentence: ', sentences_train[0])\n",
    "print('Tokenized Train Sentence: ', tokenized_train)\n",
    "print('Token Train IDs: ', tokenized_ids_train)\n",
    "\n",
    "# Print the original val sentence; tokenized and IDs mapped.\n",
    "print('Original Val Sentence: ', sentences_val[0])\n",
    "print('Tokenized Train Sentence: ', tokenized_val)\n",
    "print('Token Train IDs: ', tokenized_ids_val)\n"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Loading XLMRobertaTokenizer ...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b7ecfe365e4e3d955cd5d6dbfacb54",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Original Train Sentence:  nen á vist bolest vztek smutek zmatek osam ě lost beznad ě j a nakonec jen klid Asi takhle vypad á m ů j life\n",
      "Tokenized Train Sentence:  ['▁nen', '▁á', '▁vist', '▁bolest', '▁vz', 'tek', '▁smut', 'ek', '▁z', 'ma', 'tek', '▁osam', '▁', 'ě', '▁lost', '▁bez', 'nad', '▁', 'ě', '▁j', '▁a', '▁nakonec', '▁jen', '▁klid', '▁Asi', '▁takhle', '▁vy', 'pad', '▁á', '▁m', '▁', 'ů', '▁j', '▁life']\n",
      "Token Train IDs:  [73351, 392, 18591, 112616, 10682, 2142, 67456, 343, 97, 192, 2142, 99892, 6, 2353, 72856, 1209, 9169, 6, 2353, 1647, 10, 95002, 7349, 122166, 37933, 167809, 1154, 4299, 392, 347, 6, 1170, 1647, 6897]\n",
      "Original Val Sentence:  modi mantrimandal may samil honay par badhai narmaday har\n",
      "Tokenized Train Sentence:  ['▁modi', '▁man', 'tri', 'man', 'dal', '▁may', '▁sam', 'il', '▁ho', 'nay', '▁par', '▁bad', 'hai', '▁na', 'rma', 'day', '▁har']\n",
      "Token Train IDs:  [43381, 332, 3996, 669, 2465, 1543, 1289, 379, 739, 13650, 366, 6494, 15251, 24, 17668, 5636, 182]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "R9BCSqmTSpCT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605394189990,
     "user_tz": 420,
     "elapsed": 3410,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "4303fd35-187e-43d4-963f-444300070843",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids_train = []\n",
    "attention_masks_train = []\n",
    "input_ids_val = []\n",
    "attention_masks_val = []\n",
    "\n",
    "# Loop through sentences for Train and Val datasets\n",
    "for sent in sentences_train:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 160,           # Pad & truncate all sentences.\n",
    "                        padding = 'max_length',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # Add its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
    "\n",
    "for sent in sentences_val:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 160,\n",
    "                        padding = 'max_length',\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "\n",
    "    input_ids_val.append(encoded_dict['input_ids'])\n",
    "    attention_masks_val.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "# Convert the lists into tensors.\n",
    "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
    "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
    "labels_train = torch.tensor(labels_train)\n",
    "\n",
    "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
    "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
    "labels_val = torch.tensor(labels_val)\n",
    "\n",
    "print('Original train sentence \\n: ', sentences_train[0])\n",
    "print('Train Token IDs \\n:', input_ids_train)\n",
    "print('Train labels: \\n', labels_train)\n",
    "print('Train sentence shape:', np.shape(sentences_train))\n",
    "print('Train token shape:', np.shape(input_ids_train))\n",
    "print('Train token mask shape:', np.shape(attention_masks_train))\n",
    "print('Train label shape:', np.shape(labels_train))\n",
    "print('\\n')\n",
    "print('Original val sentence \\n: ', sentences_val[0])\n",
    "print('Val Token IDs \\n:', input_ids_val[0])\n",
    "print('Val labels: \\n', labels_val)\n",
    "print('Train sentence shape:', np.shape(sentences_val))\n",
    "print('Train token shape:', np.shape(input_ids_val))\n",
    "print('Train token mask shape:', np.shape(attention_masks_val))\n",
    "print('Train label shape:', np.shape(labels_val))\n"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Original train sentence \n",
      ":  nen á vist bolest vztek smutek zmatek osam ě lost beznad ě j a nakonec jen klid Asi takhle vypad á m ů j life\n",
      "Train Token IDs \n",
      ": tensor([[     0,  73351,    392,  ...,      1,      1,      1],\n",
      "        [     0,   1391,     66,  ...,      1,      1,      1],\n",
      "        [     0, 113976,   2450,  ...,      1,      1,      1],\n",
      "        ...,\n",
      "        [     0,  92010,   7643,  ...,      1,      1,      1],\n",
      "        [     0,  49191,  49191,  ...,      1,      1,      1],\n",
      "        [     0, 114775,     13,  ...,      1,      1,      1]])\n",
      "Train labels: \n",
      " tensor([1, 1, 0,  ..., 2, 2, 1])\n",
      "Train sentence shape: (13935,)\n",
      "Train token shape: torch.Size([13935, 160])\n",
      "Train token mask shape: torch.Size([13935, 160])\n",
      "Train label shape: torch.Size([13935])\n",
      "\n",
      "\n",
      "Original val sentence \n",
      ":  modi mantrimandal may samil honay par badhai narmaday har\n",
      "Val Token IDs \n",
      ": tensor([    0, 43381,   332,  3996,   669,  2465,  1543,  1289,   379,   739,\n",
      "        13650,   366,  6494, 15251,    24, 17668,  5636,   182,     2,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n",
      "Val labels: \n",
      " tensor([2, 0, 0,  ..., 1, 0, 1])\n",
      "Train sentence shape: (2988,)\n",
      "Train token shape: torch.Size([2988, 160])\n",
      "Train token mask shape: torch.Size([2988, 160])\n",
      "Train label shape: torch.Size([2988])\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "2e2I0JTDSpCX"
   },
   "source": [
    "## Train and Validate"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "USjSdMBsSpCY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605394200374,
     "user_tz": 420,
     "elapsed": 440,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    }
   },
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "val_dataset = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ZvE0PB1HSpCa"
   },
   "source": [
    "## Train Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "66la17ARSpCa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605394239470,
     "user_tz": 420,
     "elapsed": 36892,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "2f258588-7b7c-4aa6-8cd6-f4ce8a28c165",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d1e9a71fdb634b1d87c4e218a0fb9910",
      "a4846c41c1fa4aaa87bce227b543e5d3",
      "5542e0feea1e4e3eb148a60ea5664b69",
      "1f151561e0a445e981a638e0a57d5ec7",
      "6413695f7ed34b55b6f99bee78167c81",
      "5f6061b7ed3948cabbf0502b94c51eac",
      "13b84960c1eb4aa6a1b16100169837a7",
      "91f8c6c889844ecc9e814fa58259d019",
      "01dc2d915c1940e192794e7e7ec87510",
      "f4fef47096c244ada00d977c1781b974",
      "2f282310f3fb4b86825cd9f76fca5373",
      "73e2eccfe6724fd18b05d819f4b14b3b",
      "4d00c38ad68a48e0865f736e90e97d7a",
      "d4a7c5861e654694b59e67f5bb6e2f27",
      "91d21b99273c47deaf1c763548f9a4a1",
      "bf51f6bc4c7d46f79de55e6d42b4b7eb"
     ]
    }
   },
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e9a71fdb634b1d87c4e218a0fb9910",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dc2d915c1940e192794e7e7ec87510",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VmERDbh4SpCf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605394689304,
     "user_tz": 420,
     "elapsed": 312,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "3ef298de-feeb-412d-837d-c481ce7906a3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "The XLMRoberta model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "roberta.embeddings.word_embeddings.weight               (250002, 768)\n",
      "roberta.embeddings.position_embeddings.weight             (514, 768)\n",
      "roberta.embeddings.token_type_embeddings.weight             (1, 768)\n",
      "roberta.embeddings.LayerNorm.weight                           (768,)\n",
      "roberta.embeddings.LayerNorm.bias                             (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
      "roberta.encoder.layer.0.attention.self.query.bias             (768,)\n",
      "roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
      "roberta.encoder.layer.0.attention.self.key.bias               (768,)\n",
      "roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
      "roberta.encoder.layer.0.attention.self.value.bias             (768,)\n",
      "roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
      "roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
      "roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
      "roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n",
      "roberta.encoder.layer.0.output.dense.bias                     (768,)\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.dense.weight                                   (768, 768)\n",
      "classifier.dense.bias                                         (768,)\n",
      "classifier.out_proj.weight                                  (3, 768)\n",
      "classifier.out_proj.bias                                        (3,)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HbXxV7MSpCh"
   },
   "source": [
    "## Optimizer & Learning Rate Scheduler\n",
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the BERT paper):\n",
    "Batch size: 16, 32\n",
    "Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
    "Number of epochs: 2, 3, 4\n",
    "We chose:\n",
    "Batch size: 32 (set when creating our DataLoaders)\n",
    "Learning rate: 2e-5\n",
    "Epochs: 4 (we'll see that this is probably too many...)\n",
    "The epsilon parameter eps = 1e-8 is \"a very small number to prevent any division by zero in the implementation\" (from here).\n",
    "You can find the creation of the AdamW optimizer in run_glue.py here."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "mkI-rp8tSpCi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605394850516,
     "user_tz": 420,
     "elapsed": 252,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    }
   },
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 3e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "sTm4jMyqSpCk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605395148252,
     "user_tz": 420,
     "elapsed": 303,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    }
   },
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 5\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "JaAHhCaaSpCm"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "trTchzN6SpCn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605395150787,
     "user_tz": 420,
     "elapsed": 326,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "18n0nAG1SpCo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605395155306,
     "user_tz": 420,
     "elapsed": 277,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    }
   },
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kFtqw2mTSpCq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605397740643,
     "user_tz": 420,
     "elapsed": 2306556,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "06724943-4102-44f8-c0c2-7b85a8422d62",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of    436.    Elapsed: 0:00:38.\n",
      "  Batch    80  of    436.    Elapsed: 0:01:19.\n",
      "  Batch   120  of    436.    Elapsed: 0:01:58.\n",
      "  Batch   160  of    436.    Elapsed: 0:02:38.\n",
      "  Batch   200  of    436.    Elapsed: 0:03:17.\n",
      "  Batch   240  of    436.    Elapsed: 0:03:57.\n",
      "  Batch   280  of    436.    Elapsed: 0:04:37.\n",
      "  Batch   320  of    436.    Elapsed: 0:05:17.\n",
      "  Batch   360  of    436.    Elapsed: 0:05:57.\n",
      "  Batch   400  of    436.    Elapsed: 0:06:36.\n",
      "\n",
      "  Average training loss: 0.95\n",
      "  Training epcoh took: 0:07:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.58\n",
      "  Validation Loss: 0.88\n",
      "  Validation took: 0:00:29\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of    436.    Elapsed: 0:00:40.\n",
      "  Batch    80  of    436.    Elapsed: 0:01:20.\n",
      "  Batch   120  of    436.    Elapsed: 0:01:59.\n",
      "  Batch   160  of    436.    Elapsed: 0:02:39.\n",
      "  Batch   200  of    436.    Elapsed: 0:03:19.\n",
      "  Batch   240  of    436.    Elapsed: 0:03:59.\n",
      "  Batch   280  of    436.    Elapsed: 0:04:38.\n",
      "  Batch   320  of    436.    Elapsed: 0:05:18.\n",
      "  Batch   360  of    436.    Elapsed: 0:05:58.\n",
      "  Batch   400  of    436.    Elapsed: 0:06:37.\n",
      "\n",
      "  Average training loss: 0.83\n",
      "  Training epcoh took: 0:07:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.60\n",
      "  Validation Loss: 0.84\n",
      "  Validation took: 0:00:29\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of    436.    Elapsed: 0:00:40.\n",
      "  Batch    80  of    436.    Elapsed: 0:01:19.\n",
      "  Batch   120  of    436.    Elapsed: 0:01:59.\n",
      "  Batch   160  of    436.    Elapsed: 0:02:39.\n",
      "  Batch   200  of    436.    Elapsed: 0:03:19.\n",
      "  Batch   240  of    436.    Elapsed: 0:03:58.\n",
      "  Batch   280  of    436.    Elapsed: 0:04:38.\n",
      "  Batch   320  of    436.    Elapsed: 0:05:18.\n",
      "  Batch   360  of    436.    Elapsed: 0:05:58.\n",
      "  Batch   400  of    436.    Elapsed: 0:06:37.\n",
      "\n",
      "  Average training loss: 0.75\n",
      "  Training epcoh took: 0:07:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.62\n",
      "  Validation Loss: 0.85\n",
      "  Validation took: 0:00:29\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of    436.    Elapsed: 0:00:40.\n",
      "  Batch    80  of    436.    Elapsed: 0:01:19.\n",
      "  Batch   120  of    436.    Elapsed: 0:01:59.\n",
      "  Batch   160  of    436.    Elapsed: 0:02:39.\n",
      "  Batch   200  of    436.    Elapsed: 0:03:19.\n",
      "  Batch   240  of    436.    Elapsed: 0:03:58.\n",
      "  Batch   280  of    436.    Elapsed: 0:04:38.\n",
      "  Batch   320  of    436.    Elapsed: 0:05:18.\n",
      "  Batch   360  of    436.    Elapsed: 0:05:57.\n",
      "  Batch   400  of    436.    Elapsed: 0:06:37.\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:07:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.61\n",
      "  Validation Loss: 0.91\n",
      "  Validation took: 0:00:29\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of    436.    Elapsed: 0:00:40.\n",
      "  Batch    80  of    436.    Elapsed: 0:01:19.\n",
      "  Batch   120  of    436.    Elapsed: 0:01:59.\n",
      "  Batch   160  of    436.    Elapsed: 0:02:39.\n",
      "  Batch   200  of    436.    Elapsed: 0:03:18.\n",
      "  Batch   240  of    436.    Elapsed: 0:03:58.\n",
      "  Batch   280  of    436.    Elapsed: 0:04:38.\n",
      "  Batch   320  of    436.    Elapsed: 0:05:17.\n",
      "  Batch   360  of    436.    Elapsed: 0:05:57.\n",
      "  Batch   400  of    436.    Elapsed: 0:06:37.\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:07:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.62\n",
      "  Validation Loss: 0.94\n",
      "  Validation took: 0:00:29\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:38:26 (h:mm:ss)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "JdEl06v7SpCs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605398023669,
     "user_tz": 420,
     "elapsed": 303,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "9e7346d4-f5f4-4f85-9786-9232b7986d4f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0:07:12</td>\n",
       "      <td>0:00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0:07:13</td>\n",
       "      <td>0:00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0:07:13</td>\n",
       "      <td>0:00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0:07:12</td>\n",
       "      <td>0:00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0:07:12</td>\n",
       "      <td>0:00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.95         0.88           0.58       0:07:12         0:00:29\n",
       "2               0.83         0.84           0.60       0:07:13         0:00:29\n",
       "3               0.75         0.85           0.62       0:07:13         0:00:29\n",
       "4               0.67         0.91           0.61       0:07:12         0:00:29\n",
       "5               0.60         0.94           0.62       0:07:12         0:00:29"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "UtV3Mm0TSpCu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1605398133740,
     "user_tz": 420,
     "elapsed": 621,
     "user": {
      "displayName": "Ryan GOSSR",
      "photoUrl": "",
      "userId": "06989976719428488766"
     }
    },
    "outputId": "466beae0-333c-474e-d5ec-e139540424aa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  }
 ]
}